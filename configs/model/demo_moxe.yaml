num_experts: 8
top_k_experts: 2
num_layers: 2
moe_layer_type: "moxe"
router_type: "conditioned_addition"
expert_type: "xlstm"
modulation_bias: "proportional"
gate_bias: true
gamma: 0.7
eps: 0.0000001
difficulty_threshold: 0.9
ffn_dim: 128
group_wise_loss: "kl_div"

xlstm:
  pad_token_id: 1
  vocab_size: 48
  context_length: 10
  num_blocks: 1
  embedding_dim: 32
  # slstm_at: [1]

  mlstm_block:
    mlstm:
      conv1d_kernel_size: 4
      qkv_proj_blocksize: 32
      num_heads: 2

  slstm_block:
    slstm:
      backend: "vanilla"
      num_heads: 2
      conv1d_kernel_size: 4
      bias_init: "powerlaw_blockdependent"

    feedforward:
      proj_factor: 1.7
      act_fn: "swish"
